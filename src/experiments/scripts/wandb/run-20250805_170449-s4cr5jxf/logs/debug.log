2025-08-05 17:04:50,435 INFO    MainThread:4092268 [wandb_init.py:setup_run_log_directory():703] Logging user logs to /home/argy/extractor/src/experiments/scripts/wandb/run-20250805_170449-s4cr5jxf/logs/debug.log
2025-08-05 17:04:50,435 INFO    MainThread:4092268 [wandb_init.py:setup_run_log_directory():704] Logging internal logs to /home/argy/extractor/src/experiments/scripts/wandb/run-20250805_170449-s4cr5jxf/logs/debug-internal.log
2025-08-05 17:04:50,435 INFO    MainThread:4092268 [wandb_init.py:init():831] calling init triggers
2025-08-05 17:04:50,436 INFO    MainThread:4092268 [wandb_init.py:init():836] wandb.init called with sweep_config: {}
config: {'config': '/home/argy/extractor/src/experiments/configs/baseline_2.yaml', 'dataset_name': None, 'dataset_config_name': None, 'train_file': '/home/argy/extractor/data/CL/syntactic_stages_train.txt', 'validation_file': '/home/argy/extractor/data/test.txt', 'validation_split_percentage': 5, 'model_name_or_path': None, 'config_name': 'gpt2', 'tokenizer_name': 'gpt2', 'use_slow_tokenizer': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'learning_rate': 0.000188, 'weight_decay': 0.0, 'num_train_epochs': 1, 'max_train_steps': None, 'gradient_accumulation_steps': 2, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'num_warmup_steps': 0, 'output_dir': './outputs/gpt2-babyLM/baseline_2_seed858531', 'seed': 858531, 'model_type': 'gpt2', 'block_size': None, 'preprocessing_num_workers': None, 'overwrite_cache': False, 'no_keep_linebreaks': False, 'push_to_hub': False, 'hub_model_id': None, 'hub_token': None, 'trust_remote_code': False, 'checkpointing_steps': None, 'resume_from_checkpoint': None, 'with_tracking': True, 'report_to': 'wandb', 'manual_shuffle': True, 'condition_name': 'baseline_2', '_wandb': {}}
